import seaborn as sn
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import pandas as pd
data=pd.read_csv('data.csv')
print(data.columns)
print(data.isna().sum())
print(data.describe())
print(data.info())
col=data.columns.values
data['z-scores']=(data.asm_commands_add-data.asm_commands_add.mean())/(data.asm_commands_add.std())
df=data[(data['z-scores'] >-3)&(data['z-scores']<3)]
q1=df.asm_commands_add.quantile(0.25)
q3=df.asm_commands_add.quantile(0.75)
iqr=q3-q1
upper=q3+1.5*iqr
lower=q1-1.5*iqr

df=df[(df.asm_commands_add < upper)&(df.asm_commands_add >lower)]
q_1=df.asm_commands_add.quantile(0.25)
q_3=df.asm_commands_add.quantile(0.75)
iq_r=q_3-q_1
upper_=q_3+1.5*iq_r
lower_=q_1-1.5*iq_r
df=df[(df.asm_commands_add < upper_)&(df.asm_commands_add >lower_)]

q_11=df.asm_commands_add.quantile(0.25)
q_33=df.asm_commands_add.quantile(0.75)
i_r=q_33-q_11
upper_bound=q_33+1.5*i_r
lower_bound=q_11-1.5*i_r
df=df[(df.asm_commands_add < upper_bound)&(df.asm_commands_add >lower_bound)]

q11=df.asm_commands_add.quantile(0.25)
q33=df.asm_commands_add.quantile(0.75)
ir=q33-q11
upperbound=q33+1.5*ir
lowerbound=q11-1.5*ir
df=df[(df.asm_commands_add < upperbound)&(df.asm_commands_add >lowerbound)]

q111=df.asm_commands_add.quantile(0.25)
q333=df.asm_commands_add.quantile(0.75)
i=q333-q111
upperbounds=q333+1.5*i
lowerbounds=q111-1.5*i
df=df[(df.asm_commands_add < upperbounds)&(df.asm_commands_add >lowerbounds)]

q1111=df.asm_commands_add.quantile(0.25)
q3333=df.asm_commands_add.quantile(0.75)
ii=q3333-q1111
upperboundss=q3333+1.5*ii
lowerboundss=q1111-1.5*ii
df=df[(df.asm_commands_add < upperboundss)&(df.asm_commands_add >lowerboundss)]

q=df.asm_commands_add.quantile(0.25)
Q=df.asm_commands_add.quantile(0.75)
I=q-q
upperboun=q+1.5*I
lowerboundss=Q-1.5*I
df=df[(df.asm_commands_add < upperboundss)&(df.asm_commands_add >lowerboundss)]

print('------------------------------')
df['z-scores']=(df.asm_commands_call-df.asm_commands_call.mean())/(data.asm_commands_call.std())
df=df[(df['z-scores'] >-3)&(df['z-scores']<3)]
q1_1=df.asm_commands_call.quantile(0.25)
q3_3=df.asm_commands_call.quantile(0.75)
ii_qr=q3_3-q1_1
uppe_r=q3_3+1.5*ii_qr
lowe_r=q1_1-1.5*ii_qr
df=df[(df.asm_commands_call < uppe_r)&(df.asm_commands_add >lowe_r)]

df['z-scores']=(df.asm_commands_cld-df.asm_commands_cld.mean())/(data.asm_commands_cld.std())
df=df[(df['z-scores'] >-3)&(df['z-scores']<3)]
qi_1=df.asm_commands_cld.quantile(0.25)
qi_3=df.asm_commands_cld.quantile(0.75)
i1=qi_3-qi_1
up=qi_3+1.5*i1
lo=qi_1-1.5*i1
df=df[(df.asm_commands_cld <up)&(df.asm_commands_cld >lo)]

qii_1=df.asm_commands_cld.quantile(0.25)
qii_3=df.asm_commands_cld.quantile(0.75)
i11=qii_3-qii_1
uppi=qii_3+1.5*i11
lowe=qii_1-1.5*i11
df=df[(df.asm_commands_cld <uppi)&(df.asm_commands_cld >lowe)]

df['z-scores']=(df.asm_commands_cli-df.asm_commands_cli.mean())/(data.asm_commands_cli.std())
df=df[(df['z-scores'] >-3)&(df['z-scores']<3)]
qiq_1=df.asm_commands_cli.quantile(0.25)
qiq_3=df.asm_commands_cli.quantile(0.75)
i1q=qiq_3-qiq_1
upq=qiq_3+1.5*i1q
loq=qiq_1-1.5*i1q
df=df[(df.asm_commands_cli <upq)&(df.asm_commands_cli >loq)]

qiiq_1=df.asm_commands_cli.quantile(0.25)
qiiq_3=df.asm_commands_cli.quantile(0.75)
i11q=qiiq_3-qiiq_1
uppiq=qiiq_3+1.5*i11q
loweq=qiiq_1-1.5*i11q
df=df[(df.asm_commands_cli <uppiq)&(df.asm_commands_cli >loweq)]
colm=df.select_dtypes(include='number').columns.values
#for i in colm:
#    sn.boxplot(df[i])
#    plt.show()
print(data.shape)
print(df.shape)
lab=LabelEncoder()
df['class']=lab.fit_transform(df['Class'])
x=df[['asm_commands_add','asm_commands_cld','asm_commands_cli','asm_commands_cmp','asm_commands_daa','asm_commands_dec','asm_commands_fchs','asm_commands_cdq','asm_commands_call','asm_commands_push','asm_commands_sal','line_count_asm','size_asm',
      'asm_commands_in','asm_commands_inc','asm_commands_jnb','asm_commands_jz','asm_commands_or','asm_commands_rep','asm_commands_ret','asm_commands_stc'
      ,'asm_commands_stos','asm_commands_test']]
colms=['asm_commands_add','asm_commands_cld','asm_commands_cli','asm_commands_cmp','asm_commands_daa','asm_commands_dec','asm_commands_fchs','asm_commands_cdq','asm_commands_call','asm_commands_push','asm_commands_sal','line_count_asm','size_asm',
      'asm_commands_in','asm_commands_inc','asm_commands_jnb','asm_commands_jz','asm_commands_or','asm_commands_rep','asm_commands_ret','asm_commands_stc'
      ,'asm_commands_stos','asm_commands_test']
'''for i in colms:
    for j in colms:
        plt.plot(df[i],marker='o',label=f'{i}',color='red')
        plt.plot(df[j],marker='x',label=f'{j}',color='blue')
        plt.title(f'{i} vs  {j}')
        plt.legend()
        plt.show()
sn.countplot(data['Class'])
plt.show()'''
y=df['class']
print(y.value_counts())
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)
logistic=LogisticRegression()
logistic.fit(x_train,y_train)
print(logistic.score(x_test,y_test))
from xgboost import XGBClassifier
xgb=XGBClassifier()
xgb.fit(x_train,y_train)
x=df[['asm_commands_add','asm_commands_cld','asm_commands_cli','asm_commands_cdq','asm_commands_call','asm_commands_push','asm_commands_daa','asm_commands_sal','line_count_asm','size_asm',]]
y=pd.get_dummies(df['Class'])
print(xgb.score(x_test,y_test))
X=df[['asm_commands_add','asm_commands_cld','asm_commands_cli','asm_commands_cmp','asm_commands_daa','asm_commands_dec','asm_commands_fchs','asm_commands_cdq','asm_commands_call','asm_commands_push','asm_commands_sal','line_count_asm','size_asm',
      'asm_commands_in','asm_commands_inc','asm_commands_jnb','asm_commands_jz','asm_commands_or','asm_commands_rep','asm_commands_ret','asm_commands_stc'
      ,'asm_commands_stos','asm_commands_test']]
Y=pd.get_dummies(df['class'])
x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25)
from keras.models import Sequential
from keras.layers import Dense
import keras.activations,keras.losses
models=Sequential()
models.add(Dense(units=x.shape[1],input_dim=x_test.shape[1],activation=keras.activations.softmax))
models.add(Dense(units=x.shape[1],activation=keras.activations.softmax))
models.add(Dense(units=x.shape[1],activation=keras.activations.softmax))
models.add(Dense(units=x.shape[1],activation=keras.activations.softmax))
models.add(Dense(units=x.shape[1],activation=keras.activations.softmax))
models.add(Dense(units=9,activation=keras.activations.softmax))
models.compile(optimizer='rmsprop',loss=keras.losses.categorical_crossentropy,metrics='accuracy')
models.fit(x_train,y_train,batch_size=20,epochs=350)